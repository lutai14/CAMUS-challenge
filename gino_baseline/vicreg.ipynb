{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import monai\n",
    "from unet import UNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from torchvision.transforms.functional import resize, center_crop\n",
    "from torchvision.transforms import InterpolationMode\n",
    "from vicreg import VICReg, train_vicreg\n",
    "\n",
    "class CamusDataset(Dataset):\n",
    "    def __init__(self, data_path, image_size=(512, 512)):\n",
    "        super().__init__()\n",
    "        self.root = data_path\n",
    "\n",
    "        self.data_list = []\n",
    "        self.image_size = image_size\n",
    "\n",
    "        self.num_imgs = len(os.listdir(self.root))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_imgs\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        chambers = '2CH' if torch.rand(1) > 0.5 else '4CH'\n",
    "\n",
    "        path = os.path.join(self.root, f'patient{idx+1:04d}', f'patient{idx+1:04d}_{chambers}_sequence')\n",
    "\n",
    "        image_sitk = sitk.ReadImage(f'{path}.mhd', sitk.sitkFloat32)\n",
    "\n",
    "        # get pixel spacing to correct aspect ratio\n",
    "        spacing = image_sitk.GetSpacing()\n",
    "        aspect_ratio = spacing[1]/spacing[0]\n",
    "\n",
    "        # convert to numpy\n",
    "\n",
    "        first_frame_index = torch.randint(0, image_sitk.GetSize()[2] - 2, (1,))\n",
    "\n",
    "        image_1 = sitk.GetArrayFromImage(image_sitk)[first_frame_index] / 255\n",
    "        image_2 = sitk.GetArrayFromImage(image_sitk)[first_frame_index + 1] / 255\n",
    "\n",
    "\n",
    "\n",
    "        # compute aspect ratio of pixel(mm) and image(pixels)\n",
    "        pixel_aspect = spacing[1] / spacing[0]\n",
    "        image_aspect = image_sitk.GetHeight() / image_sitk.GetWidth()\n",
    "\n",
    "        # preprocess image and mask\n",
    "\n",
    "        image_1, image_2 = torch.Tensor(image_1).unsqueeze(0), torch.Tensor(image_2).unsqueeze(0)\n",
    "        size =  (self.image_size[0], int(image_1.shape[2]*image_aspect*pixel_aspect))\n",
    "\n",
    "        image_1  = resize(image_1, size, interpolation=InterpolationMode.BICUBIC)\n",
    "        image_2 = resize(image_2, size, interpolation=InterpolationMode.NEAREST)\n",
    "\n",
    "        image_1, image_2 = center_crop(image_1, self.image_size), center_crop(image_2, self.image_size)\n",
    "\n",
    "        image = torch.cat((image_1, image_2), dim=0)\n",
    "\n",
    "        return image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset = CamusDataset('../data/training')\n",
    "model = UNet(n_channels=1, n_classes=4, bilinear=False, scaling=4)\n",
    "vicreg = VICReg(model)\n",
    "loader = utils.data.DataLoader(dataset, batch_size=5, shuffle=True)\n",
    "optimizer = optim.Adam(vicreg.parameters(), lr=5e-5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 0\n",
      "Batch 0 loss: 94.20459747314453\n",
      "Batch 5 loss: 73.82655334472656\n",
      "Batch 10 loss: 62.79039001464844\n",
      "Batch 15 loss: 55.23118591308594\n",
      "Batch 20 loss: 44.032386779785156\n",
      "Batch 25 loss: 39.59077453613281\n",
      "Batch 30 loss: 33.03168869018555\n",
      "Batch 35 loss: 31.54857635498047\n",
      "Batch 40 loss: 31.135936737060547\n",
      "Batch 45 loss: 26.35281753540039\n",
      "Batch 50 loss: 26.801044464111328\n",
      "Batch 55 loss: 23.837892532348633\n",
      "Batch 60 loss: 24.75250244140625\n",
      "Batch 65 loss: 27.436601638793945\n",
      "Batch 70 loss: 24.447341918945312\n",
      "Batch 75 loss: 24.478166580200195\n",
      "Batch 80 loss: 24.483457565307617\n",
      "Batch 85 loss: 23.345046997070312\n",
      "Starting epoch 1\n",
      "Batch 0 loss: 23.533626556396484\n",
      "Batch 5 loss: 23.666913986206055\n",
      "Batch 10 loss: 23.509546279907227\n",
      "Batch 15 loss: 23.921009063720703\n",
      "Batch 20 loss: 23.253942489624023\n",
      "Batch 25 loss: 23.20338249206543\n",
      "Batch 30 loss: 23.162216186523438\n",
      "Batch 35 loss: 23.9178524017334\n",
      "Batch 40 loss: 23.756580352783203\n",
      "Batch 45 loss: 23.528400421142578\n",
      "Batch 50 loss: 23.062162399291992\n",
      "Batch 55 loss: 23.199466705322266\n",
      "Batch 60 loss: 23.138870239257812\n",
      "Batch 65 loss: 23.831819534301758\n",
      "Batch 70 loss: 26.76825714111328\n",
      "Batch 75 loss: 23.44320297241211\n",
      "Batch 80 loss: 23.24160385131836\n",
      "Batch 85 loss: 23.213830947875977\n",
      "Starting epoch 2\n",
      "Batch 0 loss: 23.066028594970703\n",
      "Batch 5 loss: 23.391035079956055\n",
      "Batch 10 loss: 23.025558471679688\n",
      "Batch 15 loss: 23.048492431640625\n",
      "Batch 20 loss: 23.082439422607422\n",
      "Batch 25 loss: 23.132986068725586\n",
      "Batch 30 loss: 24.182966232299805\n",
      "Batch 35 loss: 23.30194664001465\n",
      "Batch 40 loss: 23.072965621948242\n",
      "Batch 45 loss: 23.133289337158203\n",
      "Batch 50 loss: 23.0920352935791\n",
      "Batch 55 loss: 23.44405174255371\n",
      "Batch 60 loss: 23.05707359313965\n",
      "Batch 65 loss: 23.080204010009766\n",
      "Batch 70 loss: 23.14606475830078\n",
      "Batch 75 loss: 23.207874298095703\n",
      "Batch 80 loss: 23.05428695678711\n",
      "Batch 85 loss: 23.341096878051758\n",
      "Starting epoch 3\n",
      "Batch 0 loss: 23.156436920166016\n",
      "Batch 5 loss: 23.06490707397461\n",
      "Batch 10 loss: 23.0806941986084\n",
      "Batch 15 loss: 23.045976638793945\n",
      "Batch 20 loss: 23.409141540527344\n",
      "Batch 25 loss: 23.055105209350586\n",
      "Batch 30 loss: 23.187143325805664\n",
      "Batch 35 loss: 23.07067108154297\n",
      "Batch 40 loss: 23.40345001220703\n",
      "Batch 45 loss: 23.04218101501465\n",
      "Batch 50 loss: 23.105884552001953\n",
      "Batch 55 loss: 23.26510238647461\n",
      "Batch 60 loss: 23.03286361694336\n",
      "Batch 65 loss: 23.06877326965332\n",
      "Batch 70 loss: 23.045482635498047\n",
      "Batch 75 loss: 23.141746520996094\n",
      "Batch 80 loss: 23.112062454223633\n",
      "Batch 85 loss: 23.078216552734375\n",
      "Starting epoch 4\n",
      "Batch 0 loss: 23.07503890991211\n",
      "Batch 5 loss: 23.041770935058594\n",
      "Batch 10 loss: 23.420862197875977\n",
      "Batch 15 loss: 23.260101318359375\n",
      "Batch 20 loss: 23.02805519104004\n",
      "Batch 25 loss: 23.07935905456543\n",
      "Batch 30 loss: 23.223278045654297\n",
      "Batch 35 loss: 23.1009521484375\n",
      "Batch 40 loss: 23.0493106842041\n",
      "Batch 45 loss: 23.342456817626953\n",
      "Batch 50 loss: 23.113109588623047\n",
      "Batch 55 loss: 23.075414657592773\n",
      "Batch 60 loss: 23.076343536376953\n",
      "Batch 65 loss: 23.021677017211914\n",
      "Batch 70 loss: 23.050138473510742\n",
      "Batch 75 loss: 23.120134353637695\n",
      "Batch 80 loss: 23.089332580566406\n",
      "Batch 85 loss: 23.04697036743164\n",
      "Starting epoch 5\n",
      "Batch 0 loss: 23.18024253845215\n",
      "Batch 5 loss: 23.06365394592285\n",
      "Batch 10 loss: 23.07155990600586\n",
      "Batch 15 loss: 23.068492889404297\n",
      "Batch 20 loss: 23.01608657836914\n",
      "Batch 25 loss: 23.1126651763916\n",
      "Batch 30 loss: 23.04210662841797\n",
      "Batch 35 loss: 23.078357696533203\n",
      "Batch 40 loss: 23.342363357543945\n",
      "Batch 45 loss: 23.052352905273438\n",
      "Batch 50 loss: 23.051822662353516\n",
      "Batch 55 loss: 23.125408172607422\n",
      "Batch 60 loss: 23.043052673339844\n",
      "Batch 65 loss: 23.069015502929688\n",
      "Batch 70 loss: 23.03012466430664\n",
      "Batch 75 loss: 23.078018188476562\n",
      "Batch 80 loss: 23.05924415588379\n",
      "Batch 85 loss: 23.118831634521484\n",
      "Starting epoch 6\n",
      "Batch 0 loss: 23.062463760375977\n",
      "Batch 5 loss: 23.017581939697266\n",
      "Batch 10 loss: 23.06658172607422\n",
      "Batch 15 loss: 23.021949768066406\n",
      "Batch 20 loss: 23.01331901550293\n",
      "Batch 25 loss: 23.061317443847656\n",
      "Batch 30 loss: 23.032878875732422\n",
      "Batch 35 loss: 23.090362548828125\n",
      "Batch 40 loss: 23.13286781311035\n",
      "Batch 45 loss: 23.05826759338379\n",
      "Batch 50 loss: 23.043577194213867\n",
      "Batch 55 loss: 23.0390625\n",
      "Batch 60 loss: 23.09918212890625\n",
      "Batch 65 loss: 23.0400390625\n",
      "Batch 70 loss: 23.369125366210938\n",
      "Batch 75 loss: 23.065189361572266\n",
      "Batch 80 loss: 23.031906127929688\n",
      "Batch 85 loss: 23.148529052734375\n",
      "Starting epoch 7\n",
      "Batch 0 loss: 23.405197143554688\n",
      "Batch 5 loss: 23.028217315673828\n",
      "Batch 10 loss: 23.038875579833984\n",
      "Batch 15 loss: 23.102182388305664\n",
      "Batch 20 loss: 23.083721160888672\n",
      "Batch 25 loss: 23.085447311401367\n",
      "Batch 30 loss: 23.194862365722656\n",
      "Batch 35 loss: 23.149309158325195\n",
      "Batch 40 loss: 23.196430206298828\n",
      "Batch 45 loss: 23.3240966796875\n",
      "Batch 50 loss: 23.062053680419922\n",
      "Batch 55 loss: 23.036418914794922\n",
      "Batch 60 loss: 23.012109756469727\n",
      "Batch 65 loss: 23.00154685974121\n",
      "Batch 70 loss: 23.12082862854004\n",
      "Batch 75 loss: 23.086502075195312\n",
      "Batch 80 loss: 23.064926147460938\n",
      "Batch 85 loss: 23.151628494262695\n",
      "Starting epoch 8\n",
      "Batch 0 loss: 23.071054458618164\n",
      "Batch 5 loss: 23.01519775390625\n",
      "Batch 10 loss: 23.033145904541016\n",
      "Batch 15 loss: 23.089075088500977\n",
      "Batch 20 loss: 23.02347755432129\n",
      "Batch 25 loss: 23.146404266357422\n",
      "Batch 30 loss: 23.160707473754883\n",
      "Batch 35 loss: 23.033418655395508\n",
      "Batch 40 loss: 23.054561614990234\n",
      "Batch 45 loss: 23.0346736907959\n",
      "Batch 50 loss: 23.065597534179688\n",
      "Batch 55 loss: 23.007862091064453\n",
      "Batch 60 loss: 23.067371368408203\n",
      "Batch 65 loss: 23.159465789794922\n",
      "Batch 70 loss: 23.132383346557617\n",
      "Batch 75 loss: 23.063125610351562\n",
      "Batch 80 loss: 23.032217025756836\n",
      "Batch 85 loss: 23.036226272583008\n",
      "Starting epoch 9\n",
      "Batch 0 loss: 23.032955169677734\n",
      "Batch 5 loss: 23.332151412963867\n",
      "Batch 10 loss: 23.085294723510742\n",
      "Batch 15 loss: 23.080331802368164\n",
      "Batch 20 loss: 23.098684310913086\n",
      "Batch 25 loss: 23.017436981201172\n",
      "Batch 30 loss: 23.060455322265625\n",
      "Batch 35 loss: 23.02535629272461\n",
      "Batch 40 loss: 23.023296356201172\n",
      "Batch 45 loss: 23.340612411499023\n",
      "Batch 50 loss: 23.057497024536133\n",
      "Batch 55 loss: 23.147613525390625\n",
      "Batch 60 loss: 23.075481414794922\n",
      "Batch 65 loss: 23.01692008972168\n",
      "Batch 70 loss: 23.074628829956055\n",
      "Batch 75 loss: 23.136716842651367\n",
      "Batch 80 loss: 23.05368423461914\n",
      "Batch 85 loss: 22.98956298828125\n"
     ]
    }
   ],
   "source": [
    "vicreg, losses = train_vicreg(vicreg, loader, optimizer, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "torch.save(vicreg.encoder.state_dict(), 'models/vicreg_encoder.pth')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}