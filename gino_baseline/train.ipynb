{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034d33f1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training a basic segmentation algorithm in Pytorch Lightning\n",
    "\n",
    "In this python notebook, I will outline a barebones Pytorch Lightning (PL) implementation of training a network for the CAMUS echocardiography segmentation challenge.\n",
    "\n",
    "Pytorch Lightning is a library that is completely built on Pytorch, but it re-organizes pytorch code into something more concise and readable.\n",
    "\n",
    "Just like in Pytorch, PL starts with defining an architecture as a class-object. In addition, we must also define a training and validation step as a class-function -- such that later we can simply call trainer.fit(). PL has scripted the rest for us, which spares us a lot of boiler-plate coding.\n",
    "\n",
    "So, we define a model as follows, note that we inherit the pl.LightningModule base class intead of torch.nn.Module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05dd9e22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import monai\n",
    "from unet import UNet\n",
    "from metrics import *\n",
    "\n",
    "# define the LightningModule\n",
    "class SegmentationModel(pl.LightningModule):\n",
    "    def __init__(self, out_path_test='./test_results/', pretrained_weights=None):\n",
    "        super().__init__()\n",
    "        self.pretrained_weights = pretrained_weights\n",
    "        self.model = UNet(n_channels=1, n_classes=4, bilinear=False, scaling=4)\n",
    "        if pretrained_weights:\n",
    "            self.model.load_state_dict(torch.load(pretrained_weights))\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.out_path_test = out_path_test\n",
    "        \n",
    "        \n",
    "    def forward(self, x, method='train'):\n",
    "        if method=='train':\n",
    "            return self.model.forward(x)\n",
    "        elif method=='ssl':\n",
    "            return self.model.forward_ssl(x)\n",
    "        else:\n",
    "            print('method not recognized')\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        if self.current_epoch < 2 and self.pretrained_weights:\n",
    "            # Freeze model encoder weights\n",
    "            for param in self.model.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            # Unfreeze model encoder weights\n",
    "            for param in self.model.encoder.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x) #self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        # Logging (to TensorBoard  by default)\n",
    "        dice_loss_train =  dice_loss(y_hat, y)\n",
    "\n",
    "        self.log(\"loss\", {'train': loss.item() } )\n",
    "        self.log(\"dice_loss\", {'train': dice_loss_train.item() } )\n",
    "\n",
    "        return loss  \n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        hs_distances = calculate_hausdorff_distance(y_hat.cpu().detach(),\n",
    "                                         y.cpu().detach())\n",
    "        dice_loss_train =  dice_loss(y_hat, y)\n",
    "        self.log(\"loss\", {'val': loss })\n",
    "        self.log(\"dice_loss\", {'val': dice_loss_train.item() } )\n",
    "        self.log(\"hs_distance region 1\", {'val': hs_distances[0].item() } )\n",
    "        self.log(\"hs_distance region 2\", {'val': hs_distances[1].item() } )\n",
    "        self.log(\"hs_distance region 3\", {'val': hs_distances[2].item() } )\n",
    "        self.log(\"hs_distance region 4\", {'val': hs_distances[3].item() } )\n",
    "        self.log(\"hs_distance average\", {'val': np.mean(hs_distances) } )\n",
    "        return loss    \n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=3e-4)\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def predict_step(self, sample, sample_idx):\n",
    "        x, y = sample  # INCOMPATIBLE WITH batch_size > 1\n",
    "\n",
    "        y_hat = self.forward(x)\n",
    "        \n",
    "        # log results as images\n",
    "        fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, figsize=(16,9));\n",
    "\n",
    "        ax0.set_title('prediction', fontsize=30)\n",
    "        ax1.set_title('ground truth', fontsize=30)\n",
    "        ax2.set_title('image', fontsize=30)\n",
    "\n",
    "        ax0.imshow(y_hat.cpu().argmax(dim=1)[0], vmax=3); ax0.axis('off')\n",
    "        ax1.imshow(y[0].cpu(),  vmax=3); ax1.axis('off')\n",
    "        ax2.imshow(x[0, 0].cpu(), cmap='Greys_r'); ax2.axis('off')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        tensorboard = self.logger.experiment\n",
    "        tensorboard.add_figure('inference results', fig, sample_idx)\n",
    "        \n",
    "        \n",
    "    def test_step(self, sample, sample_idx):\n",
    "        x, x_attrs, info = sample # INCOMPATIBLE WITH batch_size > 1\n",
    "        \n",
    "        # pad until divisible by 2^n (because of n up- and downsampling steps):\n",
    "        two_n = 16\n",
    "        row_pad = (-x.shape[-2]) % two_n\n",
    "        col_pad = (-x.shape[-1]) % two_n\n",
    "        x_padded = F.pad(x, (col_pad, 0, row_pad, 0))\n",
    "        \n",
    "        y_hat = self.forward(x_padded)[:, :, row_pad:, col_pad:]\n",
    "\n",
    "        \n",
    "        # log results to Tensorboard:\n",
    "        fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(11,9));\n",
    "\n",
    "        ax0.set_title('prediction', fontsize=30)\n",
    "        ax1.set_title('image', fontsize=30)\n",
    "        \n",
    "        ax0.imshow(y_hat.cpu().argmax(dim=1)[0], vmax=3); ax0.axis('off')\n",
    "        ax1.imshow(x[0, 0].cpu(), cmap='Greys_r'); ax1.axis('off')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        tensorboard = self.logger.experiment\n",
    "        tensorboard.add_figure('test results', fig, sample_idx)\n",
    "        \n",
    "        # write output to mhd+raw files (but first convert to sitk):\n",
    "        mask = TF.resize(y_hat, x_attrs['shape'], InterpolationMode.BICUBIC)\n",
    "        mask = mask.argmax(dim=1, keepdim=True).type(torch.uint8)[0]\n",
    "        \n",
    "        mask_sitk = sitk.GetImageFromArray(mask.cpu().numpy())\n",
    "        mask_sitk.SetSpacing([x.item() for x in x_attrs['spacing']])\n",
    "\n",
    "        filename = \"_\".join(x[0] for x in info[:3]) + '.mhd'\n",
    "        out_path = os.path.join(self.out_path_test, filename)\n",
    "\n",
    "        writer = sitk.ImageFileWriter()\n",
    "        writer.SetFileName(out_path)\n",
    "        writer.Execute(mask_sitk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# init the model\n",
    "pretrained_weights = './models/vicreg_encoder.pth' # Choose either this or None\n",
    "#pretrained_weights = None\n",
    "model = SegmentationModel(pretrained_weights=pretrained_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "af4aa552",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As a next step, we need to define a dataset class. This is one is identical to a pytorch dataset object: we simply define how we want to load our data samples, and make them retrievable by defining indices. \n",
    "\n",
    "To organize the data, I recurse through the dataset directories, and put the relevant info in a Pandas dataframe (df). Every row in the df represents one image, and calling their row index will retrieve the image and mask data with the __getitem__ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from torchvision.transforms.functional import resize, center_crop\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CamusDataset(Dataset):\n",
    "    def __init__(self, data_path, image_size=(512, 512)):\n",
    "        super().__init__()\n",
    "        self.root = data_path\n",
    "\n",
    "        self.data_list = []\n",
    "        self.image_size = image_size\n",
    "\n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for file in files:\n",
    "                if file.split('_')[-1] == 'gt.mhd':\n",
    "                    sample = file.split('_')[:3] # [patient, view, ED/ES]\n",
    "                    self.data_list.append(sample)\n",
    "        self.df = pd.DataFrame(self.data_list, columns=['patient', 'view', 'ED/ES'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = list(self.df.loc[idx])\n",
    "        path = os.path.join(self.root, row[0], \"_\".join(row))\n",
    "        image_sitk = sitk.ReadImage(f'{path}.mhd', sitk.sitkFloat32)\n",
    "\n",
    "        # get pixel spacing to correct aspect ratio\n",
    "        spacing = image_sitk.GetSpacing()\n",
    "        aspect_ratio = spacing[1]/spacing[0]\n",
    "\n",
    "        # convert to numpy\n",
    "        image = sitk.GetArrayFromImage(image_sitk) / 255\n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(f'{path}_gt.mhd', sitk.sitkFloat32))\n",
    "\n",
    "        # compute aspect ratio of pixel(mm) and image(pixels)\n",
    "        pixel_aspect = spacing[1] / spacing[0]\n",
    "        image_aspect = image_sitk.GetHeight() / image_sitk.GetWidth()\n",
    "\n",
    "        # preprocess image and mask\n",
    "        image, mask = torch.Tensor(image), torch.Tensor(mask)\n",
    "        size =  (self.image_size[0], int(image.shape[2]*image_aspect*pixel_aspect))\n",
    "\n",
    "        image  = resize(image, size, interpolation=InterpolationMode.BICUBIC)\n",
    "        mask = resize(mask, size, interpolation=InterpolationMode.NEAREST)\n",
    "\n",
    "        image, mask = center_crop(image, self.image_size), center_crop(mask, self.image_size)\n",
    "        mask = mask.squeeze()\n",
    "\n",
    "        return image, mask.to(torch.long)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "932ffcc8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we instantiate the dataset object, and split the data into a training and validation set.\n",
    "The dataloaders control how the data will be batched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8523b8c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# init dataset object\n",
    "dataset = CamusDataset(data_path=r\"../data/training\", image_size=(512, 512))\n",
    "\n",
    "# split into train and validation set, by splitting indices:\n",
    "\n",
    "indices = np.arange(len(dataset))\n",
    "train_indices, val_indices = train_test_split(indices, random_state=42)\n",
    "\n",
    "\n",
    "# init samplers: \n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# init loaders: (set num_workers to 8 * number of gpus, 0 for debugging)\n",
    "train_loader = utils.data.DataLoader(dataset, sampler=train_sampler, batch_size=5, num_workers=0)\n",
    "val_loader = utils.data.DataLoader(dataset, sampler=val_sampler, batch_size=5, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453861b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we define a trainer, which takes care of the rest. We train by simply calling trainer.fit(): \n",
    "\n",
    "Run ```tensorboard --logdir=lightning_logs --samples_per_plugin images=200``` in your (anaconda/bash) terminal to track the loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "802f6989",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:448: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | UNet             | 1.9 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.769     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14ecf996c579406bb86a3914288ce43c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95c2192b229b45a89f68916480475f37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ece0f8ed2d842ae8561226b815d0762"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "026d9e38b65047ceb6fbfa3d748a9d5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bda48d6327547668f74726b71a95d33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5e9b6c94c024216bd1a578d0dff9deb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2971d0d3c2742329db75433bef9072e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a60f941874e14ab4b00f59bf0cf2806d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5393f86675a24ac5b49ae7cd46cbcfa3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e0b46b83dea4d3aaa71314751c0deaf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c21f773b8e4741d6b9df88ed4a5857c5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce7f0024b0c841e8ae777bb533abe7e2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f353f56f836b4588967f0710cb219bac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4a7b8f034e448359b593b638a3dc4ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40d8e62346fd4136a031bdb83a0fa85c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "22abbc2502824e138af5cd32b1fb38af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "113c7e3008bd4b5c8c882dae174b127d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a0e16bdd4ca4e39b189ebd106c2445a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "abc8d2be12324f41b3bd5c0bf0c57887"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e6b417354a241e7beea7a86fb81dc55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3e66e42d2db43c9873a7bf9df26f37b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "663e4a58444d42a2b348a619a32255c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "560448a0486a48c48d44b98a3bc0cdd0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c3cff76adbd4d1d9382c72d4adf3d5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8974ff49244244a28041e3caf2a1e183"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec84282d05d040258c16f90460d790db"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71e95fb2da2c47fd8448ae2f98a99e5d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    }
   ],
   "source": [
    "# train the model: cc 0.26 after 1 epoch\n",
    "trainer = pl.Trainer(max_epochs=25, gpus=1)#, limit_train_batches=10)\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "# Save the model\n",
    "model_name = 'unet.pth' if pretrained_weights is None else 'ssl_unet_pretrained.pth'\n",
    "trainer.save_checkpoint('./models/'+model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6372b7f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's display some (validation) results in Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88a17dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1390: UserWarning: `.predict(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.predict(ckpt_path='best')` to use the best model or `.predict(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  + f\" You can pass `.{fn}(ckpt_path='best')` to use the best model or\"\n",
      "Restoring states from the checkpoint path at /home/tin/Documents/GitHub/CAMUS-challenge/gino_baseline/lightning_logs/version_0/checkpoints/epoch=24-step=6750.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/tin/Documents/GitHub/CAMUS-challenge/gino_baseline/lightning_logs/version_0/checkpoints/epoch=24-step=6750.ckpt\n",
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: 270it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03c473273e5546d5ba609a582dc256ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/prediction_epoch_loop.py:135: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
      "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n"
     ]
    }
   ],
   "source": [
    "# automatically auto-loads the best weights from the previous run\n",
    "val_loader_log = utils.data.DataLoader(dataset, sampler=val_sampler, batch_size=1, num_workers=0)\n",
    "outputs = trainer.predict(dataloaders=val_loader_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b45d782",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, if we're happy with the results, we should run our network on the test set, and save the resulting masks in a format that's compatible with the CAMUS challenge website (The website allows 4 test submissions).\n",
    "\n",
    "\n",
    "First we need to adjust the dataset class, as the ```__getitem__``` method shouldn't try to load a ground truth mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89393bbb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CamusTestSet(Dataset):\n",
    "    def __init__(self, data_path, image_size=(512, 512)):\n",
    "        super().__init__()\n",
    "        self.root = data_path\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for file in files:\n",
    "                suffix = file.split('_')[-1]\n",
    "                if suffix in ['ED.mhd', 'ES.mhd']:\n",
    "                    sample = file.split('.')[0].split('_')[:3] # [patient, view, ED/ES]\n",
    "                    self.data_list.append(sample)\n",
    "        self.df = pd.DataFrame(self.data_list, columns=['patient', 'view', 'ED/ES'])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = list(self.df.loc[idx])\n",
    "        path = os.path.join(self.root, row[0], \"_\".join(row))\n",
    "        \n",
    "        image_sitk = sitk.ReadImage(f'{path}.mhd', sitk.sitkFloat32)\n",
    "        image = sitk.GetArrayFromImage(image_sitk) / 255\n",
    "        \n",
    "        # get pixel spacing to correct aspect ratio\n",
    "        spacing = image_sitk.GetSpacing()\n",
    "        pixel_aspect = spacing[1]/spacing[0]\n",
    "        image_aspect = image_sitk.GetHeight() / image_sitk.GetWidth()\n",
    "        \n",
    "        # preprocess image\n",
    "        image = torch.Tensor(image)\n",
    "        size =  (self.image_size[0], int(image.shape[2]*image_aspect*pixel_aspect))\n",
    "        image  = resize(image, size, interpolation=InterpolationMode.BICUBIC)\n",
    "        \n",
    "        image_attrs = dict(\n",
    "            shape = [image_sitk.GetHeight(), image_sitk.GetWidth()],\n",
    "            spacing = spacing\n",
    "        )\n",
    "        return image, image_attrs, row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e99cf2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we are ready to test the model. Earlier, in the model Class definition, I defined the ```test_step```, where it writes a predicted mask to an .mhd file format, which is compatible with the Challenge submission website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/tin/Documents/GitHub/CAMUS-challenge/gino_baseline/lightning_logs/version_0/checkpoints/epoch=24-step=6750.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/tin/Documents/GitHub/CAMUS-challenge/gino_baseline/lightning_logs/version_0/checkpoints/epoch=24-step=6750.ckpt\n",
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:154: UserWarning: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "  f\"Total length of `{dataloader.__class__.__name__}` across ranks is zero.\"\n"
     ]
    }
   ],
   "source": [
    "test_set = CamusTestSet(data_path=r\"C:\\Users\\Tadija\\Desktop\\data\\testing\")\n",
    "test_loader = utils.data.DataLoader(test_set, batch_size=1, num_workers=0)\n",
    "trainer.test(ckpt_path=\"best\", dataloaders=test_loader);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('camus-baseline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fde25bff22cac1da1ec8bb493443a14925b5f3cd746b39f4f5263924a6de861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}