{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034d33f1",
   "metadata": {},
   "source": [
    "### Training a basic segmentation algorithm in Pytorch Lightning\n",
    "\n",
    "In this python notebook, I will outline a barebones Pytorch Lightning (PL) implementation of training a network for the CAMUS echocardiography segmentation challenge.\n",
    "\n",
    "Pytorch Lightning is a library that is completely built on Pytorch, but it re-organizes pytorch code into something more concise and readable.\n",
    "\n",
    "Just like in Pytorch, PL starts with defining an architecture as a class-object. In addition, we must also define a training and validation step as a class-function -- such that later we can simply call trainer.fit(). PL has scripted the rest for us, which spares us a lot of boiler-plate coding.\n",
    "\n",
    "So, we define a model as follows, note that we inherit the pl.LightningModule base class intead of torch.nn.Module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05dd9e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Tadija\\miniconda3\\envs\\camus-baseline\\lib\\site-packages\\torchaudio\\backend\\utils.py:62: UserWarning: No audio backend is available.\n",
      "  warnings.warn(\"No audio backend is available.\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import monai\n",
    "\n",
    "# define the LightningModule\n",
    "class SegmentationModel(pl.LightningModule):\n",
    "    def __init__(self, out_path_test='./test_results/'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = monai.networks.nets.UNet(\n",
    "                                        spatial_dims=2,\n",
    "                                        in_channels=1,\n",
    "                                        out_channels=4,\n",
    "                                        channels=(16, 32, 64, 128, 256),\n",
    "                                        strides=(2, 2, 2, 2),\n",
    "                                        num_res_units=2,\n",
    "                                        )\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        self.out_path_test = out_path_test\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x) #self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        # Logging (to TensorBoard  by default)\n",
    "        self.log(\"loss\", {'train': loss.item() } )\n",
    "        return loss  \n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"loss\", {'val': loss })\n",
    "        return loss    \n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def predict_step(self, sample, sample_idx):\n",
    "        x, y = sample  # INCOMPATIBLE WITH batch_size > 1\n",
    "\n",
    "        y_hat = self.forward(x)\n",
    "        \n",
    "        # log results as images\n",
    "        fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, figsize=(16,9));\n",
    "\n",
    "        ax0.set_title('prediction', fontsize=30)\n",
    "        ax1.set_title('ground truth', fontsize=30)\n",
    "        ax2.set_title('image', fontsize=30)\n",
    "\n",
    "        ax0.imshow(y_hat.cpu().argmax(dim=1)[0], vmax=3); ax0.axis('off')\n",
    "        ax1.imshow(y[0].cpu(),  vmax=3); ax1.axis('off')\n",
    "        ax2.imshow(x[0, 0].cpu(), cmap='Greys_r'); ax2.axis('off')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        tensorboard = self.logger.experiment\n",
    "        tensorboard.add_figure('inference results', fig, sample_idx)\n",
    "        \n",
    "        \n",
    "    def test_step(self, sample, sample_idx):\n",
    "        x, x_attrs, info = sample # INCOMPATIBLE WITH batch_size > 1\n",
    "        \n",
    "        # pad until divisible by 2^n (because of n up- and downsampling steps):\n",
    "        two_n = 16\n",
    "        row_pad = (-x.shape[-2]) % two_n\n",
    "        col_pad = (-x.shape[-1]) % two_n\n",
    "        x_padded = F.pad(x, (col_pad, 0, row_pad, 0))\n",
    "        \n",
    "        y_hat = self.forward(x_padded)[:, :, row_pad:, col_pad:]\n",
    "\n",
    "        \n",
    "        # log results to Tensorboard:\n",
    "        fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(11,9));\n",
    "\n",
    "        ax0.set_title('prediction', fontsize=30)\n",
    "        ax1.set_title('image', fontsize=30)\n",
    "        \n",
    "        ax0.imshow(y_hat.cpu().argmax(dim=1)[0], vmax=3); ax0.axis('off')\n",
    "        ax1.imshow(x[0, 0].cpu(), cmap='Greys_r'); ax1.axis('off')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        tensorboard = self.logger.experiment\n",
    "        tensorboard.add_figure('test results', fig, sample_idx)\n",
    "        \n",
    "        # write output to mhd+raw files (but first convert to sitk):\n",
    "        mask = TF.resize(y_hat, x_attrs['shape'], InterpolationMode.BICUBIC)\n",
    "        mask = mask.argmax(dim=1, keepdim=True).type(torch.uint8)[0]\n",
    "        \n",
    "        mask_sitk = sitk.GetImageFromArray(mask.cpu().numpy())\n",
    "        mask_sitk.SetSpacing([x.item() for x in x_attrs['spacing']])\n",
    "\n",
    "        filename = \"_\".join(x[0] for x in info[:3]) + '.mhd'\n",
    "        out_path = os.path.join(self.out_path_test, filename)\n",
    "\n",
    "        writer = sitk.ImageFileWriter()\n",
    "        writer.SetFileName(out_path)\n",
    "        writer.Execute(mask_sitk)\n",
    "        \n",
    "                   \n",
    "# init the model\n",
    "model = SegmentationModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4aa552",
   "metadata": {},
   "source": [
    "As a next step, we need to define a dataset class. This is one is identical to a pytorch dataset object: we simply define how we want to load our data samples, and make them retrievable by defining indices. \n",
    "\n",
    "To organize the data, I recurse through the dataset directories, and put the relevant info in a Pandas dataframe (df). Every row in the df represents one image, and calling their row index will retrieve the image and mask data with the __getitem__ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb0f39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from torchvision.transforms.functional import resize, center_crop\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CamusDataset(Dataset):\n",
    "    def __init__(self, data_path, image_size=(512, 512)):\n",
    "        super().__init__()\n",
    "        self.root = data_path\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for file in files:\n",
    "                if file.split('_')[-1] == 'gt.mhd':\n",
    "                    sample = file.split('_')[:3] # [patient, view, ED/ES]\n",
    "                    self.data_list.append(sample)\n",
    "        self.df = pd.DataFrame(self.data_list, columns=['patient', 'view', 'ED/ES'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = list(self.df.loc[idx])\n",
    "        path = os.path.join(self.root, row[0], \"_\".join(row))\n",
    "        image_sitk = sitk.ReadImage(f'{path}.mhd', sitk.sitkFloat32)\n",
    "        \n",
    "        # get pixel spacing to correct aspect ratio\n",
    "        spacing = image_sitk.GetSpacing()\n",
    "        aspect_ratio = spacing[1]/spacing[0]\n",
    "        \n",
    "        # convert to numpy\n",
    "        image = sitk.GetArrayFromImage(image_sitk) / 255\n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(f'{path}_gt.mhd', sitk.sitkFloat32))\n",
    "        \n",
    "        # compute aspect ratio of pixel(mm) and image(pixels)\n",
    "        pixel_aspect = spacing[1] / spacing[0]\n",
    "        image_aspect = image_sitk.GetHeight() / image_sitk.GetWidth()\n",
    "        \n",
    "        # preprocess image and mask\n",
    "        image, mask = torch.Tensor(image), torch.Tensor(mask)\n",
    "        size =  (self.image_size[0], int(image.shape[2]*image_aspect*pixel_aspect))\n",
    "\n",
    "        image  = resize(image, size, interpolation=InterpolationMode.BICUBIC)\n",
    "        mask = resize(mask, size, interpolation=InterpolationMode.NEAREST)\n",
    "        \n",
    "        image, mask = center_crop(image, self.image_size), center_crop(mask, self.image_size)\n",
    "        mask = mask.squeeze()\n",
    "\n",
    "        return image, mask.to(torch.long)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ffcc8",
   "metadata": {},
   "source": [
    "Now we instantiate the dataset object, and split the data into a training and validation set.\n",
    "The dataloaders control how the data will be batched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8523b8c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "At least one array required as input",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24364\\726365075.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# init dataset object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCamusDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"C:\\Users\\Tadija\\Desktop\\data\\training\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# split into train and validation set, by splitting indices:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24364\\989997701.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data_path, image_size)\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'patient'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'view'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ED/ES'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffled_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Tadija\\miniconda3\\envs\\camus-baseline\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2413\u001b[0m     \u001b[0mn_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2414\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn_arrays\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2415\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"At least one array required as input\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2417\u001b[0m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: At least one array required as input"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# init dataset object\n",
    "dataset = CamusDataset(data_path=r\"C:\\Users\\Tadija\\Desktop\\data\\training\", image_size=(512, 512))\n",
    "\n",
    "# split into train and validation set, by splitting indices:\n",
    "\n",
    "indices = np.arange(len(dataset))\n",
    "train_indices, val_indices = train_test_split(indices, random_state=42)\n",
    "\n",
    "\n",
    "# init samplers: \n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# init loaders: (set num_workers to 8 * number of gpus, 0 for debugging)\n",
    "train_loader = utils.data.DataLoader(dataset, sampler=train_sampler, batch_size=5, num_workers=0)\n",
    "val_loader = utils.data.DataLoader(dataset, sampler=val_sampler, batch_size=5, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453861b3",
   "metadata": {},
   "source": [
    "Finally, we define a trainer, which takes care of the rest. We train by simply calling trainer.fit(): \n",
    "\n",
    "Run ```tensorboard --logdir=lightning_logs --samples_per_plugin images=200``` in your (anaconda/bash) terminal to track the loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f6989",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model:\n",
    "trainer = pl.Trainer(max_epochs=20, gpus=1)#, limit_train_batches=10)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6372b7f",
   "metadata": {},
   "source": [
    "Let's display some (validation) results in Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88a17dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically auto-loads the best weights from the previous run\n",
    "val_loader_log = utils.data.DataLoader(dataset, sampler=val_sampler, batch_size=1, num_workers=0)\n",
    "outputs = trainer.predict(dataloaders=val_loader_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b45d782",
   "metadata": {},
   "source": [
    "Finally, if we're happy with the results, we should run our network on the test set, and save the resulting masks in a format that's compatible with the CAMUS challenge website (The website allows 4 test submissions).\n",
    "\n",
    "\n",
    "First we need to adjust the dataset class, as the ```__getitem__``` method shouldn't try to load a ground truth mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89393bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CamusTestSet(Dataset):\n",
    "    def __init__(self, data_path, image_size=(512, 512)):\n",
    "        super().__init__()\n",
    "        self.root = data_path\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for file in files:\n",
    "                suffix = file.split('_')[-1]\n",
    "                if suffix in ['ED.mhd', 'ES.mhd']:\n",
    "                    sample = file.split('.')[0].split('_')[:3] # [patient, view, ED/ES]\n",
    "                    self.data_list.append(sample)\n",
    "        self.df = pd.DataFrame(self.data_list, columns=['patient', 'view', 'ED/ES'])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = list(self.df.loc[idx])\n",
    "        path = os.path.join(self.root, row[0], \"_\".join(row))\n",
    "        \n",
    "        image_sitk = sitk.ReadImage(f'{path}.mhd', sitk.sitkFloat32)\n",
    "        image = sitk.GetArrayFromImage(image_sitk) / 255\n",
    "        \n",
    "        # get pixel spacing to correct aspect ratio\n",
    "        spacing = image_sitk.GetSpacing()\n",
    "        pixel_aspect = spacing[1]/spacing[0]\n",
    "        image_aspect = image_sitk.GetHeight() / image_sitk.GetWidth()\n",
    "        \n",
    "        # preprocess image\n",
    "        image = torch.Tensor(image)\n",
    "        size =  (self.image_size[0], int(image.shape[2]*image_aspect*pixel_aspect))\n",
    "        image  = resize(image, size, interpolation=InterpolationMode.BICUBIC)\n",
    "        \n",
    "        image_attrs = dict(\n",
    "            shape = [image_sitk.GetHeight(), image_sitk.GetWidth()],\n",
    "            spacing = spacing\n",
    "        )\n",
    "        return image, image_attrs, row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e99cf2",
   "metadata": {},
   "source": [
    "Now we are ready to test the model. Earlier, in the model Class definition, I defined the ```test_step```, where it writes a predicted mask to an .mhd file format, which is compatible with the Challenge submission website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda19e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = CamusTestSet(data_path=r\"C:\\Users\\Tadija\\Desktop\\data\\testing\")\n",
    "test_loader = utils.data.DataLoader(test_set, batch_size=1, num_workers=0)\n",
    "trainer.test(ckpt_path=\"best\", dataloaders=test_loader);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76af012b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('camus-baseline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fde25bff22cac1da1ec8bb493443a14925b5f3cd746b39f4f5263924a6de861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
