{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "034d33f1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Training a basic segmentation algorithm in Pytorch Lightning\n",
    "\n",
    "In this python notebook, I will outline a barebones Pytorch Lightning (PL) implementation of training a network for the CAMUS echocardiography segmentation challenge.\n",
    "\n",
    "Pytorch Lightning is a library that is completely built on Pytorch, but it re-organizes pytorch code into something more concise and readable.\n",
    "\n",
    "Just like in Pytorch, PL starts with defining an architecture as a class-object. In addition, we must also define a training and validation step as a class-function -- such that later we can simply call trainer.fit(). PL has scripted the rest for us, which spares us a lot of boiler-plate coding.\n",
    "\n",
    "So, we define a model as follows, note that we inherit the pl.LightningModule base class intead of torch.nn.Module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05dd9e22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import optim, nn, utils, Tensor\n",
    "from torchvision.transforms import ToTensor\n",
    "import pytorch_lightning as pl\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "import monai\n",
    "from unet import UNet\n",
    "\n",
    "# define the LightningModule\n",
    "class SegmentationModel(pl.LightningModule):\n",
    "    def __init__(self, out_path_test='./test_results/', pretrained_weights=None):\n",
    "        super().__init__()\n",
    "        self.pretrained_weights = pretrained_weights\n",
    "        self.model = UNet(n_channels=1, n_classes=4, bilinear=False, scaling=4)\n",
    "        if pretrained_weights:\n",
    "            self.model.load_state_dict(torch.load(pretrained_weights))\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.out_path_test = out_path_test\n",
    "        \n",
    "        \n",
    "    def forward(self, x, method='train'):\n",
    "        if method=='train':\n",
    "            return self.model.forward(x)\n",
    "        elif method=='ssl':\n",
    "            return self.model.forward_ssl(x)\n",
    "        else:\n",
    "            print('method not recognized')\n",
    "    \n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        if self.current_epoch < 2 and self.pretrained_weights:\n",
    "            # Freeze model encoder weights\n",
    "            for param in self.model.encoder.parameters():\n",
    "                param.requires_grad = False\n",
    "        else:\n",
    "            # Unfreeze model encoder weights\n",
    "            for param in self.model.encoder.parameters():\n",
    "                param.requires_grad = True\n",
    "\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x) #self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        # Logging (to TensorBoard  by default)\n",
    "        self.log(\"loss\", {'train': loss.item() } )\n",
    "        return loss  \n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"loss\", {'val': loss })\n",
    "        return loss    \n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=2e-4)\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def predict_step(self, sample, sample_idx):\n",
    "        x, y = sample  # INCOMPATIBLE WITH batch_size > 1\n",
    "\n",
    "        y_hat = self.forward(x)\n",
    "        \n",
    "        # log results as images\n",
    "        fig, (ax0, ax1, ax2) = plt.subplots(nrows=1, ncols=3, figsize=(16,9));\n",
    "\n",
    "        ax0.set_title('prediction', fontsize=30)\n",
    "        ax1.set_title('ground truth', fontsize=30)\n",
    "        ax2.set_title('image', fontsize=30)\n",
    "\n",
    "        ax0.imshow(y_hat.cpu().argmax(dim=1)[0], vmax=3); ax0.axis('off')\n",
    "        ax1.imshow(y[0].cpu(),  vmax=3); ax1.axis('off')\n",
    "        ax2.imshow(x[0, 0].cpu(), cmap='Greys_r'); ax2.axis('off')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        tensorboard = self.logger.experiment\n",
    "        tensorboard.add_figure('inference results', fig, sample_idx)\n",
    "        \n",
    "        \n",
    "    def test_step(self, sample, sample_idx):\n",
    "        x, x_attrs, info = sample # INCOMPATIBLE WITH batch_size > 1\n",
    "        \n",
    "        # pad until divisible by 2^n (because of n up- and downsampling steps):\n",
    "        two_n = 16\n",
    "        row_pad = (-x.shape[-2]) % two_n\n",
    "        col_pad = (-x.shape[-1]) % two_n\n",
    "        x_padded = F.pad(x, (col_pad, 0, row_pad, 0))\n",
    "        \n",
    "        y_hat = self.forward(x_padded)[:, :, row_pad:, col_pad:]\n",
    "\n",
    "        \n",
    "        # log results to Tensorboard:\n",
    "        fig, (ax0, ax1) = plt.subplots(nrows=1, ncols=2, figsize=(11,9));\n",
    "\n",
    "        ax0.set_title('prediction', fontsize=30)\n",
    "        ax1.set_title('image', fontsize=30)\n",
    "        \n",
    "        ax0.imshow(y_hat.cpu().argmax(dim=1)[0], vmax=3); ax0.axis('off')\n",
    "        ax1.imshow(x[0, 0].cpu(), cmap='Greys_r'); ax1.axis('off')\n",
    "        \n",
    "        fig.tight_layout()\n",
    "        \n",
    "        tensorboard = self.logger.experiment\n",
    "        tensorboard.add_figure('test results', fig, sample_idx)\n",
    "        \n",
    "        # write output to mhd+raw files (but first convert to sitk):\n",
    "        mask = TF.resize(y_hat, x_attrs['shape'], InterpolationMode.BICUBIC)\n",
    "        mask = mask.argmax(dim=1, keepdim=True).type(torch.uint8)[0]\n",
    "        \n",
    "        mask_sitk = sitk.GetImageFromArray(mask.cpu().numpy())\n",
    "        mask_sitk.SetSpacing([x.item() for x in x_attrs['spacing']])\n",
    "\n",
    "        filename = \"_\".join(x[0] for x in info[:3]) + '.mhd'\n",
    "        out_path = os.path.join(self.out_path_test, filename)\n",
    "\n",
    "        writer = sitk.ImageFileWriter()\n",
    "        writer.SetFileName(out_path)\n",
    "        writer.Execute(mask_sitk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# init the model\n",
    "pretrained_weights = './models/vicreg_encoder.pth'\n",
    "model = SegmentationModel(pretrained_weights=None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "af4aa552",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "As a next step, we need to define a dataset class. This is one is identical to a pytorch dataset object: we simply define how we want to load our data samples, and make them retrievable by defining indices. \n",
    "\n",
    "To organize the data, I recurse through the dataset directories, and put the relevant info in a Pandas dataframe (df). Every row in the df represents one image, and calling their row index will retrieve the image and mask data with the __getitem__ method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcb0f39c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from torchvision.transforms.functional import resize, center_crop\n",
    "from torchvision.transforms import InterpolationMode\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class CamusDataset(Dataset):\n",
    "    def __init__(self, data_path, image_size=(512, 512)):\n",
    "        super().__init__()\n",
    "        self.root = data_path\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for file in files:\n",
    "                if file.split('_')[-1] == 'gt.mhd':\n",
    "                    sample = file.split('_')[:3] # [patient, view, ED/ES]\n",
    "                    self.data_list.append(sample)\n",
    "        self.df = pd.DataFrame(self.data_list, columns=['patient', 'view', 'ED/ES'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = list(self.df.loc[idx])\n",
    "        path = os.path.join(self.root, row[0], \"_\".join(row))\n",
    "        image_sitk = sitk.ReadImage(f'{path}.mhd', sitk.sitkFloat32)\n",
    "        \n",
    "        # get pixel spacing to correct aspect ratio\n",
    "        spacing = image_sitk.GetSpacing()\n",
    "        aspect_ratio = spacing[1]/spacing[0]\n",
    "        \n",
    "        # convert to numpy\n",
    "        image = sitk.GetArrayFromImage(image_sitk) / 255\n",
    "        mask = sitk.GetArrayFromImage(sitk.ReadImage(f'{path}_gt.mhd', sitk.sitkFloat32))\n",
    "        \n",
    "        # compute aspect ratio of pixel(mm) and image(pixels)\n",
    "        pixel_aspect = spacing[1] / spacing[0]\n",
    "        image_aspect = image_sitk.GetHeight() / image_sitk.GetWidth()\n",
    "        \n",
    "        # preprocess image and mask\n",
    "        image, mask = torch.Tensor(image), torch.Tensor(mask)\n",
    "        size =  (self.image_size[0], int(image.shape[2]*image_aspect*pixel_aspect))\n",
    "\n",
    "        image  = resize(image, size, interpolation=InterpolationMode.BICUBIC)\n",
    "        mask = resize(mask, size, interpolation=InterpolationMode.NEAREST)\n",
    "        \n",
    "        image, mask = center_crop(image, self.image_size), center_crop(mask, self.image_size)\n",
    "        mask = mask.squeeze()\n",
    "\n",
    "        return image, mask.to(torch.long)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932ffcc8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we instantiate the dataset object, and split the data into a training and validation set.\n",
    "The dataloaders control how the data will be batched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8523b8c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "# init dataset object\n",
    "dataset = CamusDataset(data_path=r\"../data/training\", image_size=(512, 512))\n",
    "\n",
    "# split into train and validation set, by splitting indices:\n",
    "\n",
    "indices = np.arange(len(dataset))\n",
    "train_indices, val_indices = train_test_split(indices, random_state=42)\n",
    "\n",
    "\n",
    "# init samplers: \n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "val_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "# init loaders: (set num_workers to 8 * number of gpus, 0 for debugging)\n",
    "train_loader = utils.data.DataLoader(dataset, sampler=train_sampler, batch_size=5, num_workers=0)\n",
    "val_loader = utils.data.DataLoader(dataset, sampler=val_sampler, batch_size=5, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453861b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, we define a trainer, which takes care of the rest. We train by simply calling trainer.fit(): \n",
    "\n",
    "Run ```tensorboard --logdir=lightning_logs --samples_per_plugin images=200``` in your (anaconda/bash) terminal to track the loss over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "802f6989",
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:448: LightningDeprecationWarning: Setting `Trainer(gpus=1)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=1)` instead.\n",
      "  f\"Setting `Trainer(gpus={gpus!r})` is deprecated in v1.7 and will be removed\"\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | model     | UNet             | 1.9 M \n",
      "1 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "1.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.9 M     Total params\n",
      "7.769     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b2463f9ec7e4e80b647122311abfac8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n",
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7f8b172972f4cf9bab75388098c567d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f37531329e247da86d935b33ca75093"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa530a9aa465496bbd35bef013a5fb62"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6cd21c87f5e940d3baf5cbc28341780a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c31ede1dfe44ade836d6ffd8b9e24f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "847048781e004df19bc0865abbc8cb9f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "980e0237b4714953a21dbf16473a90d3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e1335221c7b94edb8606ff055f82be43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "85d065d7491f4192bcadbf1155939aed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8223a05ef57481eb2cccf2168dd3944"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a118af6d05a4f54a0b7dd27d55e2cb0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03b6b290b056493091bc2b00ba631fc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4dcf51f88b74e04831efb3612a8030c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b99d86c3ab14916a10b4873f19687f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9ff9d88b9eae4229a3d1cc1e41d0ff07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78619ec22e624a7fbf55dbfd33c10154"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=15` reached.\n"
     ]
    }
   ],
   "source": [
    "# train the model: cc 0.26 after 1 epoch\n",
    "trainer = pl.Trainer(max_epochs=15, gpus=1)#, limit_train_batches=10)\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6372b7f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's display some (validation) results in Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88a17dd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py:1390: UserWarning: `.predict(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.predict(ckpt_path='best')` to use the best model or `.predict(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
      "  + f\" You can pass `.{fn}(ckpt_path='best')` to use the best model or\"\n",
      "Restoring states from the checkpoint path at /home/tin/Documents/GitHub/CAMUS-challenge/gino_baseline/lightning_logs/version_6/checkpoints/epoch=14-step=4050.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/tin/Documents/GitHub/CAMUS-challenge/gino_baseline/lightning_logs/version_6/checkpoints/epoch=14-step=4050.ckpt\n",
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:241: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  category=PossibleUserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: 270it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8aeac30c3bbb4cfcb3b385ca78c333e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/prediction_epoch_loop.py:135: UserWarning: predict returned None if it was on purpose, ignore this warning...\n",
      "  self._warning_cache.warn(\"predict returned None if it was on purpose, ignore this warning...\")\n"
     ]
    }
   ],
   "source": [
    "# automatically auto-loads the best weights from the previous run\n",
    "val_loader_log = utils.data.DataLoader(dataset, sampler=val_sampler, batch_size=1, num_workers=0)\n",
    "outputs = trainer.predict(dataloaders=val_loader_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b45d782",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Finally, if we're happy with the results, we should run our network on the test set, and save the resulting masks in a format that's compatible with the CAMUS challenge website (The website allows 4 test submissions).\n",
    "\n",
    "\n",
    "First we need to adjust the dataset class, as the ```__getitem__``` method shouldn't try to load a ground truth mask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89393bbb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CamusTestSet(Dataset):\n",
    "    def __init__(self, data_path, image_size=(512, 512)):\n",
    "        super().__init__()\n",
    "        self.root = data_path\n",
    "        \n",
    "        self.data_list = []\n",
    "        self.image_size = image_size\n",
    "        \n",
    "        for root, dirs, files in os.walk(self.root):\n",
    "            for file in files:\n",
    "                suffix = file.split('_')[-1]\n",
    "                if suffix in ['ED.mhd', 'ES.mhd']:\n",
    "                    sample = file.split('.')[0].split('_')[:3] # [patient, view, ED/ES]\n",
    "                    self.data_list.append(sample)\n",
    "        self.df = pd.DataFrame(self.data_list, columns=['patient', 'view', 'ED/ES'])\n",
    "\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = list(self.df.loc[idx])\n",
    "        path = os.path.join(self.root, row[0], \"_\".join(row))\n",
    "        \n",
    "        image_sitk = sitk.ReadImage(f'{path}.mhd', sitk.sitkFloat32)\n",
    "        image = sitk.GetArrayFromImage(image_sitk) / 255\n",
    "        \n",
    "        # get pixel spacing to correct aspect ratio\n",
    "        spacing = image_sitk.GetSpacing()\n",
    "        pixel_aspect = spacing[1]/spacing[0]\n",
    "        image_aspect = image_sitk.GetHeight() / image_sitk.GetWidth()\n",
    "        \n",
    "        # preprocess image\n",
    "        image = torch.Tensor(image)\n",
    "        size =  (self.image_size[0], int(image.shape[2]*image_aspect*pixel_aspect))\n",
    "        image  = resize(image, size, interpolation=InterpolationMode.BICUBIC)\n",
    "        \n",
    "        image_attrs = dict(\n",
    "            shape = [image_sitk.GetHeight(), image_sitk.GetWidth()],\n",
    "            spacing = spacing\n",
    "        )\n",
    "        return image, image_attrs, row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e99cf2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we are ready to test the model. Earlier, in the model Class definition, I defined the ```test_step```, where it writes a predicted mask to an .mhd file format, which is compatible with the Challenge submission website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /home/tin/Documents/GitHub/CAMUS-challenge/gino_baseline/lightning_logs/version_6/checkpoints/epoch=14-step=4050.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Loaded model weights from checkpoint at /home/tin/Documents/GitHub/CAMUS-challenge/gino_baseline/lightning_logs/version_6/checkpoints/epoch=14-step=4050.ckpt\n",
      "/home/tin/miniconda3/envs/camus-baseline/lib/python3.7/site-packages/pytorch_lightning/utilities/data.py:154: UserWarning: Total length of `DataLoader` across ranks is zero. Please make sure this was your intention.\n",
      "  f\"Total length of `{dataloader.__class__.__name__}` across ranks is zero.\"\n"
     ]
    }
   ],
   "source": [
    "test_set = CamusTestSet(data_path=r\"C:\\Users\\Tadija\\Desktop\\data\\testing\")\n",
    "test_loader = utils.data.DataLoader(test_set, batch_size=1, num_workers=0)\n",
    "trainer.test(ckpt_path=\"best\", dataloaders=test_loader);"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('camus-baseline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "fde25bff22cac1da1ec8bb493443a14925b5f3cd746b39f4f5263924a6de861e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}